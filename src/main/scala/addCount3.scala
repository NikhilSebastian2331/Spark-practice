import org.apache.spark.sql.SparkSession
import org.apache.spark.sql.functions._

object addCount3 {

  def main (args: Array[String]): Unit = {

    val spark = SparkSession.builder()
      .appName("addCount3")
      .master("local")
      .getOrCreate()

    import spark.implicits._

    val input = Seq(
      ("05:49:56.604899", "10.0.0.2.54880", "10.0.0.3.5001", 2),
      ("05:49:56.604900", "10.0.0.2.54880", "10.0.0.3.5001", 2),
      ("05:49:56.604899", "10.0.0.2.54880", "10.0.0.3.5001", 2),
      ("05:49:56.604900", "10.0.0.2.54880", "10.0.0.3.5001", 2),
      ("05:49:56.604899", "10.0.0.2.54880", "10.0.0.3.5001", 2),
      ("05:49:56.604900", "10.0.0.2.54880", "10.0.0.3.5001", 2),
      ("05:49:56.604899", "10.0.0.2.54880", "10.0.0.3.5001", 2),
      ("05:49:56.604900", "10.0.0.2.54880", "10.0.0.3.5001", 2),
      ("05:49:56.604899", "10.0.0.2.54880", "10.0.0.3.5001", 2),
      ("05:49:56.604900", "10.0.0.2.54880", "10.0.0.3.5001", 2),
      ("05:49:56.604899", "10.0.0.2.54880", "10.0.0.3.5001", 2),
      ("05:49:56.604900", "10.0.0.2.54880", "10.0.0.3.5001", 2),
      ("05:49:56.604899", "10.0.0.2.54880", "10.0.0.3.5001", 2),
      ("05:49:56.604908", "10.0.0.3.5001", "10.0.0.2.54880", 2),
      ("05:49:56.604908", "10.0.0.3.5001", "10.0.0.2.54880", 2),
      ("05:49:56.604908", "10.0.0.3.5001", "10.0.0.2.54880", 2),
      ("05:49:56.604908", "10.0.0.3.5001", "10.0.0.2.54880", 2),
      ("05:49:56.604908", "10.0.0.3.5001", "10.0.0.2.54880", 2),
      ("05:49:56.604908", "10.0.0.3.5001", "10.0.0.2.54880", 2),
      ("05:49:56.604908", "10.0.0.3.5001", "10.0.0.2.54880", 2)).toDF("column0", "column1", "column2", "label")

    val res = input.groupBy("column0", "column1", "column2", "label")
      .agg(count("*").alias("count"))

    res.show()

    spark.close()

  }

}
